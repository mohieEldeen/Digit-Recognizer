{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data from CSVs files\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "#splitting the train and validation sets\n",
    "val = train.sample(frac=0.1)\n",
    "train = train.drop(train.sample(frac=0.1).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "5      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "5       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "5         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the train labels\n",
    "labels_train = train['label']\n",
    "\n",
    "#assigning the train images data\n",
    "images_train = train.iloc[:,1:]\n",
    "images_train = images_train.to_numpy()\n",
    "images_train = images_train.astype(np.uint8)\n",
    "\n",
    "#assigning the validation labels\n",
    "labels_val = val['label']\n",
    "\n",
    "#assigning the validation images data\n",
    "images_val = val.iloc[:,1:]\n",
    "images_val = images_val.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping the images from (N,784) to (N,28,28)\n",
    "images_train = images_train.reshape((37800,28,28))\n",
    "images_val = images_val.reshape((4200,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4200, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37800, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ab48bb35f8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images_train[12225],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4209\n",
       "7    3943\n",
       "3    3907\n",
       "9    3772\n",
       "0    3742\n",
       "2    3739\n",
       "6    3732\n",
       "4    3698\n",
       "8    3664\n",
       "5    3394\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the distribution of the train labels\n",
    "labels_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    496\n",
       "2    451\n",
       "3    446\n",
       "7    434\n",
       "9    431\n",
       "6    419\n",
       "8    391\n",
       "0    383\n",
       "4    381\n",
       "5    368\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the distribution of the validation labels\n",
    "labels_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor,device\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "def data_augmentation (images):\n",
    "    \"\"\"\n",
    "    This function takes a set of Ndarray images and returnes a normalized tensor of the images after some random rotations\n",
    "    \n",
    "    with some random prespective repositioning.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    augmented_images = torch.zeros(images.shape)\n",
    "    \n",
    "    image_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                               transforms.RandomRotation((-20,20)),\n",
    "                               transforms.RandomPerspective(distortion_scale=0.4,p=0.3),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize(0.1176685 , 0.2934735)\n",
    "                                         ])\n",
    "    \n",
    "    for indx , image in enumerate(images) :\n",
    "        augmented_images[indx] = image_transform(image.reshape(28,28,1))\n",
    "        \n",
    "        \n",
    "    \n",
    "    return augmented_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train_aug = data_augmentation(images_train) #apply the function on the train images\n",
    "\n",
    "labels_train = Tensor(labels_train.to_list()) #tranform the ndarray of labels to a tensor\n",
    "\n",
    "\n",
    "train_image_labels = TensorDataset( images_train_aug , labels_train ) #combining the train images and the labels\n",
    "\n",
    "#the data loader from which we will load the train images and the labels\n",
    "data_train = DataLoader(train_image_labels,batch_size=128,shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing the validation data the same as we did with the train data\n",
    "\n",
    "images_val = images_val.astype(np.uint8)\n",
    "augmented_images_val = torch.zeros(images_val.shape)\n",
    "    \n",
    "image_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(0.1325 , 0.3101)\n",
    "                                         ])\n",
    "    \n",
    "for indx , image in enumerate(images_val) :\n",
    "    augmented_images_val[indx] = image_transform(image.reshape(28,28,1))\n",
    "        \n",
    "images_val = augmented_images_val\n",
    "\n",
    "labels_val = Tensor(labels_val.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNnet(\n",
       "  (pad): ConstantPad2d(padding=(2, 2, 2, 2), value=0)\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1): Dropout(p=0.2, inplace=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (batch2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop2): Dropout(p=0.3, inplace=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (batch3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop3): Dropout(p=0.3, inplace=False)\n",
       "  (fc1): Linear(in_features=1600, out_features=800, bias=True)\n",
       "  (drop4): Dropout(p=0.3, inplace=False)\n",
       "  (fc2): Linear(in_features=800, out_features=400, bias=True)\n",
       "  (drop5): Dropout(p=0.2, inplace=False)\n",
       "  (fc3): Linear(in_features=400, out_features=100, bias=True)\n",
       "  (drop6): Dropout(p=0.2, inplace=False)\n",
       "  (fc4): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating our CNN model \n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class CNNnet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNNnet,self).__init__()\n",
    "        self.pad = nn.ConstantPad2d(2,0)\n",
    "        \n",
    "        self.conv1  = nn.Conv2d(1,16,3)\n",
    "        self.pool1  = nn.MaxPool2d(2,2)\n",
    "        self.drop1  = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.conv2  = nn.Conv2d(16,32,4)\n",
    "        self.batch2 = nn.BatchNorm2d(32)\n",
    "        self.pool2  = nn.MaxPool2d(2,2)\n",
    "        self.drop2  = nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.conv3  = nn.Conv2d(32,64,3)\n",
    "        self.batch3 = nn.BatchNorm2d(64)\n",
    "        self.pool3  = nn.MaxPool2d(2,2)\n",
    "        self.drop3  = nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.fc1    = nn.Linear(1600,800)\n",
    "        self.drop4  = nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.fc2    = nn.Linear(800,400)\n",
    "        self.drop5  = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.fc3    = nn.Linear(400,100)\n",
    "        self.drop6  = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.fc4    = nn.Linear(100 ,10)\n",
    "        \n",
    "    def forward(self , X):\n",
    "        \n",
    "        X = self.pad(X)   # (b,1,32,32)\n",
    "        \n",
    "        \n",
    "        X = self.conv1(X)  # (b,16,30,30)\n",
    "        X = F.relu(X)      # (b,16,30,30)\n",
    "        X = self.pool1(X)  # (b,16,15,15)\n",
    "        X = self.drop1(X)  # (b,16,15,15)\n",
    "        \n",
    "        X = self.pad(X)    # (b,16,19,19)\n",
    "        \n",
    "        X = self.conv2(X)  # (b,32,16,16)\n",
    "        X = self.batch2(X) # (b,32,16,16)\n",
    "        X = F.relu(X)      # (b,32,16,16)\n",
    "        X = self.pool2(X)  # (b,32, 8, 8)\n",
    "        X = self.drop2(X)  # (b,32, 8, 8)\n",
    "        \n",
    "        X = self.pad(X)    # (b,32,12,12)\n",
    "        \n",
    "        X = self.conv3(X)  # (b,64, 10, 10)\n",
    "        X = self.batch3(X) # (b,64, 10, 10)\n",
    "        X = F.relu(X)      # (b,64, 10, 10)\n",
    "        X = self.pool3(X)  # (b,64,  5,  5)\n",
    "        X = self.drop3(X)  # (b,64,  5,  5)\n",
    "        \n",
    "        X = X.view( ( X.size()[0], -1 ) )  # (b,1600)\n",
    "        \n",
    "        X = self.fc1(X)    # (b,800)\n",
    "        X = F.relu(X)      # (b,800)\n",
    "        X = self.drop4(X)  # (b,800)\n",
    "        \n",
    "        X = self.fc2(X)    # (b,400)\n",
    "        X = F.relu(X)      # (b,400)\n",
    "        X = self.drop5(X)  # (b,400)\n",
    "        \n",
    "        X = self.fc3(X)    # (b,100)\n",
    "        X = F.relu(X)      # (b,100)\n",
    "        X = self.drop6(X)  # (b,100)\n",
    "        \n",
    "        X = self.fc4(X)    # (b,10)\n",
    "        X = F.log_softmax(X,dim=1)  # (b,10)\n",
    "        \n",
    "        return X\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "net = CNNnet()   \n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining out loss function and our optimizer\n",
    "\n",
    "import torch.optim as optim\n",
    "loss = nn.NLLLoss()\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/20 epoch at batch 10 with loss 2.309046411514282  and val of  2.2787444591522217\n",
      "1/20 epoch at batch 20 with loss 2.199526143074036  and val of  2.068939447402954\n",
      "1/20 epoch at batch 30 with loss 1.8424765706062316  and val of  1.447230577468872\n",
      "1/20 epoch at batch 40 with loss 1.4429009556770325  and val of  0.9274160861968994\n",
      "1/20 epoch at batch 50 with loss 1.1417282938957214  and val of  0.7061378359794617\n",
      "1/20 epoch at batch 60 with loss 1.0059988915920257  and val of  0.543668806552887\n",
      "1/20 epoch at batch 70 with loss 0.8753390848636627  and val of  0.46005672216415405\n",
      "1/20 epoch at batch 80 with loss 0.7473428905010223  and val of  0.4071677029132843\n",
      "1/20 epoch at batch 90 with loss 0.7357594966888428  and val of  0.3186904788017273\n",
      "1/20 epoch at batch 100 with loss 0.6963527023792266  and val of  0.2756447494029999\n",
      "1/20 epoch at batch 110 with loss 0.5955925077199936  and val of  0.30221909284591675\n",
      "1/20 epoch at batch 120 with loss 0.5958645015954971  and val of  0.24547764658927917\n",
      "1/20 epoch at batch 130 with loss 0.598942169547081  and val of  0.24866138398647308\n",
      "1/20 epoch at batch 140 with loss 0.5347362011671066  and val of  0.194190114736557\n",
      "1/20 epoch at batch 150 with loss 0.5101026952266693  and val of  0.2082880437374115\n",
      "1/20 epoch at batch 160 with loss 0.5023164123296737  and val of  0.19393770396709442\n",
      "1/20 epoch at batch 170 with loss 0.4870257437229156  and val of  0.19365555047988892\n",
      "1/20 epoch at batch 180 with loss 0.4019949108362198  and val of  0.16005288064479828\n",
      "1/20 epoch at batch 190 with loss 0.4149303138256073  and val of  0.15344882011413574\n",
      "1/20 epoch at batch 200 with loss 0.4098227500915527  and val of  0.15134991705417633\n",
      "1/20 epoch at batch 210 with loss 0.4050871729850769  and val of  0.18329691886901855\n",
      "1/20 epoch at batch 220 with loss 0.4200678735971451  and val of  0.16681651771068573\n",
      "1/20 epoch at batch 230 with loss 0.3819717884063721  and val of  0.14148373901844025\n",
      "1/20 epoch at batch 240 with loss 0.37603906989097596  and val of  0.1524384468793869\n",
      "1/20 epoch at batch 250 with loss 0.36415242552757265  and val of  0.13293276727199554\n",
      "1/20 epoch at batch 260 with loss 0.35221054404973984  and val of  0.13942404091358185\n",
      "1/20 epoch at batch 270 with loss 0.31992222666740416  and val of  0.16324226558208466\n",
      "1/20 epoch at batch 280 with loss 0.37621580362319945  and val of  0.12251061201095581\n",
      "1/20 epoch at batch 290 with loss 0.3123345568776131  and val of  0.11988388746976852\n",
      "2/20 epoch at batch 10 with loss 0.33937626481056216  and val of  0.13705036044120789\n",
      "2/20 epoch at batch 20 with loss 0.3522376477718353  and val of  0.11675049364566803\n",
      "2/20 epoch at batch 30 with loss 0.2650500938296318  and val of  0.14870543777942657\n",
      "2/20 epoch at batch 40 with loss 0.28546335697174074  and val of  0.10860425978899002\n",
      "2/20 epoch at batch 50 with loss 0.3522758275270462  and val of  0.11415624618530273\n",
      "2/20 epoch at batch 60 with loss 0.3444750443100929  and val of  0.10855745524168015\n",
      "2/20 epoch at batch 70 with loss 0.2827647253870964  and val of  0.12051757425069809\n",
      "2/20 epoch at batch 80 with loss 0.3138084262609482  and val of  0.11510437726974487\n",
      "2/20 epoch at batch 90 with loss 0.314937087893486  and val of  0.10696613788604736\n",
      "2/20 epoch at batch 100 with loss 0.33240335434675217  and val of  0.10700850933790207\n",
      "2/20 epoch at batch 110 with loss 0.32287531197071073  and val of  0.10361535102128983\n",
      "2/20 epoch at batch 120 with loss 0.30066745579242704  and val of  0.09422507137060165\n",
      "2/20 epoch at batch 130 with loss 0.30806559026241304  and val of  0.10342935472726822\n",
      "2/20 epoch at batch 140 with loss 0.29420058280229566  and val of  0.10587862879037857\n",
      "2/20 epoch at batch 150 with loss 0.26410192996263504  and val of  0.1010567918419838\n",
      "2/20 epoch at batch 160 with loss 0.32293511480093  and val of  0.10125885903835297\n",
      "2/20 epoch at batch 170 with loss 0.31327536404132844  and val of  0.12330477684736252\n",
      "2/20 epoch at batch 180 with loss 0.3102183654904366  and val of  0.12482259422540665\n",
      "2/20 epoch at batch 190 with loss 0.25607587546110155  and val of  0.0946267768740654\n",
      "2/20 epoch at batch 200 with loss 0.2547766610980034  and val of  0.1007322445511818\n",
      "2/20 epoch at batch 210 with loss 0.26676411032676695  and val of  0.09461384266614914\n",
      "2/20 epoch at batch 220 with loss 0.2761369302868843  and val of  0.09421161562204361\n",
      "2/20 epoch at batch 230 with loss 0.2727021023631096  and val of  0.09891099482774734\n",
      "2/20 epoch at batch 240 with loss 0.2940002091228962  and val of  0.08559098839759827\n",
      "2/20 epoch at batch 250 with loss 0.23492329567670822  and val of  0.08937827497720718\n",
      "2/20 epoch at batch 260 with loss 0.23645675778388978  and val of  0.1053202748298645\n",
      "2/20 epoch at batch 270 with loss 0.2735798180103302  and val of  0.09000581502914429\n",
      "2/20 epoch at batch 280 with loss 0.253664992749691  and val of  0.08568518608808517\n",
      "2/20 epoch at batch 290 with loss 0.22806095629930495  and val of  0.08954988420009613\n",
      "3/20 epoch at batch 10 with loss 0.3044832289218903  and val of  0.08348638564348221\n",
      "3/20 epoch at batch 20 with loss 0.27832385152578354  and val of  0.08687037229537964\n",
      "3/20 epoch at batch 30 with loss 0.20081031173467637  and val of  0.08625133335590363\n",
      "3/20 epoch at batch 40 with loss 0.27109952419996264  and val of  0.101968914270401\n",
      "3/20 epoch at batch 50 with loss 0.2187061294913292  and val of  0.09515219181776047\n",
      "3/20 epoch at batch 60 with loss 0.2409942328929901  and val of  0.08710385859012604\n",
      "3/20 epoch at batch 70 with loss 0.26582903861999513  and val of  0.10910098254680634\n",
      "3/20 epoch at batch 80 with loss 0.2056555151939392  and val of  0.0860091969370842\n",
      "3/20 epoch at batch 90 with loss 0.2002605453133583  and val of  0.0824703574180603\n",
      "3/20 epoch at batch 100 with loss 0.22882644534111024  and val of  0.08337774872779846\n",
      "3/20 epoch at batch 110 with loss 0.24097690135240554  and val of  0.08616416901350021\n",
      "3/20 epoch at batch 120 with loss 0.2357477992773056  and val of  0.07707773894071579\n",
      "3/20 epoch at batch 130 with loss 0.21114313304424287  and val of  0.10093908756971359\n",
      "3/20 epoch at batch 140 with loss 0.24959396272897721  and val of  0.07277283072471619\n",
      "3/20 epoch at batch 150 with loss 0.20638004094362258  and val of  0.08413618803024292\n",
      "3/20 epoch at batch 160 with loss 0.1765414945781231  and val of  0.07499973475933075\n",
      "3/20 epoch at batch 170 with loss 0.2100603237748146  and val of  0.06877271085977554\n",
      "3/20 epoch at batch 180 with loss 0.23300764858722686  and val of  0.08399046957492828\n",
      "3/20 epoch at batch 190 with loss 0.23279869854450225  and val of  0.0808035358786583\n",
      "3/20 epoch at batch 200 with loss 0.21730822026729585  and val of  0.0728837177157402\n",
      "3/20 epoch at batch 210 with loss 0.2047026813030243  and val of  0.07774686813354492\n",
      "3/20 epoch at batch 220 with loss 0.2113216444849968  and val of  0.07552740722894669\n",
      "3/20 epoch at batch 230 with loss 0.20596264600753783  and val of  0.07347165793180466\n",
      "3/20 epoch at batch 240 with loss 0.23083020597696305  and val of  0.08259378373622894\n",
      "3/20 epoch at batch 250 with loss 0.189128477871418  and val of  0.06638815999031067\n",
      "3/20 epoch at batch 260 with loss 0.22054308503866196  and val of  0.07637662440538406\n",
      "3/20 epoch at batch 270 with loss 0.22234586253762245  and val of  0.0749356672167778\n",
      "3/20 epoch at batch 280 with loss 0.19104549810290336  and val of  0.07385295629501343\n",
      "3/20 epoch at batch 290 with loss 0.19155892096459864  and val of  0.0762767419219017\n",
      "4/20 epoch at batch 10 with loss 0.1727728560566902  and val of  0.07370375096797943\n",
      "4/20 epoch at batch 20 with loss 0.2090684801340103  and val of  0.07604434341192245\n",
      "4/20 epoch at batch 30 with loss 0.20917124748229982  and val of  0.06318888813257217\n",
      "4/20 epoch at batch 40 with loss 0.21068887859582902  and val of  0.08980383723974228\n",
      "4/20 epoch at batch 50 with loss 0.1911451607942581  and val of  0.06537050753831863\n",
      "4/20 epoch at batch 60 with loss 0.18683455884456635  and val of  0.08012223988771439\n",
      "4/20 epoch at batch 70 with loss 0.23621149510145187  and val of  0.06636704504489899\n",
      "4/20 epoch at batch 80 with loss 0.19914487302303313  and val of  0.06943853944540024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/20 epoch at batch 90 with loss 0.1877713069319725  and val of  0.06771129369735718\n",
      "4/20 epoch at batch 100 with loss 0.17499166429042817  and val of  0.07579629123210907\n",
      "4/20 epoch at batch 110 with loss 0.17410326823592187  and val of  0.07603803277015686\n",
      "4/20 epoch at batch 120 with loss 0.1978868968784809  and val of  0.0746118575334549\n",
      "4/20 epoch at batch 130 with loss 0.17230316549539565  and val of  0.06896357238292694\n",
      "4/20 epoch at batch 140 with loss 0.18941025733947753  and val of  0.0679580345749855\n",
      "4/20 epoch at batch 150 with loss 0.22937367409467696  and val of  0.07004525512456894\n",
      "4/20 epoch at batch 160 with loss 0.18218351528048515  and val of  0.08469696342945099\n",
      "4/20 epoch at batch 170 with loss 0.16257557310163975  and val of  0.05835748836398125\n",
      "4/20 epoch at batch 180 with loss 0.19019051715731622  and val of  0.06262319535017014\n",
      "4/20 epoch at batch 190 with loss 0.19393092542886733  and val of  0.08814908564090729\n",
      "4/20 epoch at batch 200 with loss 0.18314711451530458  and val of  0.06380301713943481\n",
      "4/20 epoch at batch 210 with loss 0.19613229110836983  and val of  0.061023253947496414\n",
      "4/20 epoch at batch 220 with loss 0.1599438115954399  and val of  0.07050497829914093\n",
      "4/20 epoch at batch 230 with loss 0.20136786475777627  and val of  0.06208987906575203\n",
      "4/20 epoch at batch 240 with loss 0.22336574345827104  and val of  0.05896827578544617\n",
      "4/20 epoch at batch 250 with loss 0.17747817374765873  and val of  0.06674394756555557\n",
      "4/20 epoch at batch 260 with loss 0.18288414254784585  and val of  0.06785320490598679\n",
      "4/20 epoch at batch 270 with loss 0.17819968983530998  and val of  0.06883151829242706\n",
      "4/20 epoch at batch 280 with loss 0.1500431403517723  and val of  0.05875157192349434\n",
      "4/20 epoch at batch 290 with loss 0.15174413844943047  and val of  0.07076035439968109\n",
      "5/20 epoch at batch 10 with loss 0.1355800949037075  and val of  0.06232171878218651\n",
      "5/20 epoch at batch 20 with loss 0.18367592208087444  and val of  0.10001218318939209\n",
      "5/20 epoch at batch 30 with loss 0.16731580719351768  and val of  0.05961994454264641\n",
      "5/20 epoch at batch 40 with loss 0.22171485126018525  and val of  0.06196577474474907\n",
      "5/20 epoch at batch 50 with loss 0.15235364511609079  and val of  0.06176288425922394\n",
      "5/20 epoch at batch 60 with loss 0.18249470517039298  and val of  0.06479845196008682\n",
      "5/20 epoch at batch 70 with loss 0.17894653081893921  and val of  0.05439624935388565\n",
      "5/20 epoch at batch 80 with loss 0.13985846117138861  and val of  0.06268452852964401\n",
      "5/20 epoch at batch 90 with loss 0.17836341112852097  and val of  0.05802057683467865\n",
      "5/20 epoch at batch 100 with loss 0.18676068857312203  and val of  0.0630670115351677\n",
      "5/20 epoch at batch 110 with loss 0.13025219440460206  and val of  0.05863894149661064\n",
      "5/20 epoch at batch 120 with loss 0.17433197498321534  and val of  0.05584898591041565\n",
      "5/20 epoch at batch 130 with loss 0.17955783680081366  and val of  0.06253357231616974\n",
      "5/20 epoch at batch 140 with loss 0.17415156364440917  and val of  0.05499264970421791\n",
      "5/20 epoch at batch 150 with loss 0.13526299968361855  and val of  0.05785112455487251\n",
      "5/20 epoch at batch 160 with loss 0.16875024922192097  and val of  0.06200277432799339\n",
      "5/20 epoch at batch 170 with loss 0.14082940779626368  and val of  0.05854472890496254\n",
      "5/20 epoch at batch 180 with loss 0.16618321239948272  and val of  0.06502293050289154\n",
      "5/20 epoch at batch 190 with loss 0.16257645338773727  and val of  0.06030847504734993\n",
      "5/20 epoch at batch 200 with loss 0.19778959453105927  and val of  0.05413766950368881\n",
      "5/20 epoch at batch 210 with loss 0.19609496891498565  and val of  0.05486581102013588\n",
      "5/20 epoch at batch 220 with loss 0.16971121206879616  and val of  0.06188616156578064\n",
      "5/20 epoch at batch 230 with loss 0.15947992354631424  and val of  0.06004689261317253\n",
      "5/20 epoch at batch 240 with loss 0.19775938019156455  and val of  0.05357348546385765\n",
      "5/20 epoch at batch 250 with loss 0.1630784399807453  and val of  0.05121057108044624\n",
      "5/20 epoch at batch 260 with loss 0.13192785084247588  and val of  0.048694051802158356\n",
      "5/20 epoch at batch 270 with loss 0.20145612880587577  and val of  0.05895568057894707\n",
      "5/20 epoch at batch 280 with loss 0.1624244637787342  and val of  0.05170956626534462\n",
      "5/20 epoch at batch 290 with loss 0.12527685165405272  and val of  0.05587343871593475\n",
      "6/20 epoch at batch 10 with loss 0.14504068121314048  and val of  0.05184993892908096\n",
      "6/20 epoch at batch 20 with loss 0.1167086724191904  and val of  0.061501964926719666\n",
      "6/20 epoch at batch 30 with loss 0.11231975108385087  and val of  0.052814166992902756\n",
      "6/20 epoch at batch 40 with loss 0.14004027470946312  and val of  0.0568450428545475\n",
      "6/20 epoch at batch 50 with loss 0.15715935826301575  and val of  0.054425109177827835\n",
      "6/20 epoch at batch 60 with loss 0.1295936733484268  and val of  0.058046724647283554\n",
      "6/20 epoch at batch 70 with loss 0.119966134801507  and val of  0.05101604759693146\n",
      "6/20 epoch at batch 80 with loss 0.12717704102396965  and val of  0.061208635568618774\n",
      "6/20 epoch at batch 90 with loss 0.15479087978601455  and val of  0.06269339472055435\n",
      "6/20 epoch at batch 100 with loss 0.17044320032000543  and val of  0.05983039736747742\n",
      "6/20 epoch at batch 110 with loss 0.15667016804218292  and val of  0.05318315699696541\n",
      "6/20 epoch at batch 120 with loss 0.17595385983586312  and val of  0.06090296059846878\n",
      "6/20 epoch at batch 130 with loss 0.17080443128943443  and val of  0.05517130717635155\n",
      "6/20 epoch at batch 140 with loss 0.1502423591911793  and val of  0.060690127313137054\n",
      "6/20 epoch at batch 150 with loss 0.1492297239601612  and val of  0.05827169492840767\n",
      "6/20 epoch at batch 160 with loss 0.1637547045946121  and val of  0.05016878619790077\n",
      "6/20 epoch at batch 170 with loss 0.15445632189512254  and val of  0.05191604420542717\n",
      "6/20 epoch at batch 180 with loss 0.1860300563275814  and val of  0.05048731714487076\n",
      "6/20 epoch at batch 190 with loss 0.13553433865308762  and val of  0.053596943616867065\n",
      "6/20 epoch at batch 200 with loss 0.1524777676910162  and val of  0.056888148188591\n",
      "6/20 epoch at batch 210 with loss 0.13006250485777854  and val of  0.04723755270242691\n",
      "6/20 epoch at batch 220 with loss 0.14737356416881084  and val of  0.060895271599292755\n",
      "6/20 epoch at batch 230 with loss 0.11323051042854786  and val of  0.05485854670405388\n",
      "6/20 epoch at batch 240 with loss 0.15201995894312859  and val of  0.05254735052585602\n",
      "6/20 epoch at batch 250 with loss 0.14992990344762802  and val of  0.04801721125841141\n",
      "6/20 epoch at batch 260 with loss 0.13969867751002313  and val of  0.05994769185781479\n",
      "6/20 epoch at batch 270 with loss 0.1300786104053259  and val of  0.056260187178850174\n",
      "6/20 epoch at batch 280 with loss 0.1853707142174244  and val of  0.06024171784520149\n",
      "6/20 epoch at batch 290 with loss 0.1602267511188984  and val of  0.06106887757778168\n",
      "7/20 epoch at batch 10 with loss 0.14474451020359994  and val of  0.053088679909706116\n",
      "7/20 epoch at batch 20 with loss 0.1755089871585369  and val of  0.05884217098355293\n",
      "7/20 epoch at batch 30 with loss 0.12811028771102428  and val of  0.06785570085048676\n",
      "7/20 epoch at batch 40 with loss 0.1491369277238846  and val of  0.05613235756754875\n",
      "7/20 epoch at batch 50 with loss 0.13874241709709167  and val of  0.058452825993299484\n",
      "7/20 epoch at batch 60 with loss 0.14454448446631432  and val of  0.05895675718784332\n",
      "7/20 epoch at batch 70 with loss 0.13084172159433366  and val of  0.056693896651268005\n",
      "7/20 epoch at batch 80 with loss 0.1276831839233637  and val of  0.058909881860017776\n",
      "7/20 epoch at batch 90 with loss 0.18147915974259377  and val of  0.04988660663366318\n",
      "7/20 epoch at batch 100 with loss 0.1253225665539503  and val of  0.04925713688135147\n",
      "7/20 epoch at batch 110 with loss 0.1316312901675701  and val of  0.06493372470140457\n",
      "7/20 epoch at batch 120 with loss 0.13476560562849044  and val of  0.04586922377347946\n",
      "7/20 epoch at batch 130 with loss 0.1457871377468109  and val of  0.05360754206776619\n",
      "7/20 epoch at batch 140 with loss 0.1327687218785286  and val of  0.053981076925992966\n",
      "7/20 epoch at batch 150 with loss 0.1070151086896658  and val of  0.050989359617233276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/20 epoch at batch 160 with loss 0.12747140862047673  and val of  0.05183647572994232\n",
      "7/20 epoch at batch 170 with loss 0.14526638612151146  and val of  0.047286201268434525\n",
      "7/20 epoch at batch 180 with loss 0.13374965414404869  and val of  0.04592294618487358\n",
      "7/20 epoch at batch 190 with loss 0.1248676098883152  and val of  0.055884405970573425\n",
      "7/20 epoch at batch 200 with loss 0.12844398692250253  and val of  0.047568559646606445\n",
      "7/20 epoch at batch 210 with loss 0.150270801410079  and val of  0.050815340131521225\n",
      "7/20 epoch at batch 220 with loss 0.12390430718660354  and val of  0.04916628450155258\n",
      "7/20 epoch at batch 230 with loss 0.13795013278722762  and val of  0.05563773587346077\n",
      "7/20 epoch at batch 240 with loss 0.1487785466015339  and val of  0.046485014259815216\n",
      "7/20 epoch at batch 250 with loss 0.13752550520002843  and val of  0.07441821694374084\n",
      "7/20 epoch at batch 260 with loss 0.14160164073109627  and val of  0.05158142372965813\n",
      "7/20 epoch at batch 270 with loss 0.12106098867952823  and val of  0.05138697847723961\n",
      "7/20 epoch at batch 280 with loss 0.17781543210148812  and val of  0.05365623161196709\n",
      "7/20 epoch at batch 290 with loss 0.10435822606086731  and val of  0.051505398005247116\n",
      "8/20 epoch at batch 10 with loss 0.12548241019248962  and val of  0.05274412781000137\n",
      "8/20 epoch at batch 20 with loss 0.1309981096535921  and val of  0.052887145429849625\n",
      "8/20 epoch at batch 30 with loss 0.16926434487104416  and val of  0.05560489743947983\n",
      "8/20 epoch at batch 40 with loss 0.12471591755747795  and val of  0.06046610698103905\n",
      "8/20 epoch at batch 50 with loss 0.15925637111067772  and val of  0.04979190602898598\n",
      "8/20 epoch at batch 60 with loss 0.11904002539813519  and val of  0.048326388001441956\n",
      "8/20 epoch at batch 70 with loss 0.15855108499526976  and val of  0.04724373668432236\n",
      "8/20 epoch at batch 80 with loss 0.09838623255491256  and val of  0.0518253929913044\n",
      "8/20 epoch at batch 90 with loss 0.14241006448864937  and val of  0.042200036346912384\n",
      "8/20 epoch at batch 100 with loss 0.12101581543684006  and val of  0.050344664603471756\n",
      "8/20 epoch at batch 110 with loss 0.1290452979505062  and val of  0.04791882634162903\n",
      "8/20 epoch at batch 120 with loss 0.11808747574687004  and val of  0.047527145594358444\n",
      "8/20 epoch at batch 130 with loss 0.11594416052103043  and val of  0.04961463436484337\n",
      "8/20 epoch at batch 140 with loss 0.12080655284225941  and val of  0.05132551118731499\n",
      "8/20 epoch at batch 150 with loss 0.12706966325640678  and val of  0.04822681099176407\n",
      "8/20 epoch at batch 160 with loss 0.12693672701716424  and val of  0.04709450528025627\n",
      "8/20 epoch at batch 170 with loss 0.12743983715772628  and val of  0.05248825252056122\n",
      "8/20 epoch at batch 180 with loss 0.10323297381401061  and val of  0.04506877437233925\n",
      "8/20 epoch at batch 190 with loss 0.146943499147892  and val of  0.046759992837905884\n",
      "8/20 epoch at batch 200 with loss 0.13915334716439248  and val of  0.05198197439312935\n",
      "8/20 epoch at batch 210 with loss 0.1070489851757884  and val of  0.04443972930312157\n",
      "8/20 epoch at batch 220 with loss 0.11941364258527756  and val of  0.051399413496255875\n",
      "8/20 epoch at batch 230 with loss 0.12058613300323487  and val of  0.044667162001132965\n",
      "8/20 epoch at batch 240 with loss 0.11960274204611779  and val of  0.047405343502759933\n",
      "8/20 epoch at batch 250 with loss 0.14075816944241523  and val of  0.0539252795279026\n",
      "8/20 epoch at batch 260 with loss 0.12512621246278285  and val of  0.054760586470365524\n",
      "8/20 epoch at batch 270 with loss 0.14933795090764762  and val of  0.047927238047122955\n",
      "8/20 epoch at batch 280 with loss 0.12261734455823899  and val of  0.048683930188417435\n",
      "8/20 epoch at batch 290 with loss 0.11975378021597863  and val of  0.05105989798903465\n",
      "9/20 epoch at batch 10 with loss 0.10865513011813163  and val of  0.05107029899954796\n",
      "9/20 epoch at batch 20 with loss 0.11251481920480728  and val of  0.0544687882065773\n",
      "9/20 epoch at batch 30 with loss 0.12824810966849326  and val of  0.05728868022561073\n",
      "9/20 epoch at batch 40 with loss 0.11806188821792603  and val of  0.05643576383590698\n",
      "9/20 epoch at batch 50 with loss 0.12558744587004184  and val of  0.05306849256157875\n",
      "9/20 epoch at batch 60 with loss 0.13633540757000445  and val of  0.051991917192935944\n",
      "9/20 epoch at batch 70 with loss 0.11523458026349545  and val of  0.04628438875079155\n",
      "9/20 epoch at batch 80 with loss 0.11449743807315826  and val of  0.050703272223472595\n",
      "9/20 epoch at batch 90 with loss 0.13034912571310997  and val of  0.05159075930714607\n",
      "9/20 epoch at batch 100 with loss 0.10672444850206375  and val of  0.05269506573677063\n",
      "9/20 epoch at batch 110 with loss 0.115224271081388  and val of  0.05250246077775955\n",
      "9/20 epoch at batch 120 with loss 0.15043091885745524  and val of  0.04610876739025116\n",
      "9/20 epoch at batch 130 with loss 0.12682612910866736  and val of  0.05563719570636749\n",
      "9/20 epoch at batch 140 with loss 0.13467306643724442  and val of  0.04729611054062843\n",
      "9/20 epoch at batch 150 with loss 0.1447572872042656  and val of  0.042494356632232666\n",
      "9/20 epoch at batch 160 with loss 0.1151069801300764  and val of  0.04806051030755043\n",
      "9/20 epoch at batch 170 with loss 0.105739850923419  and val of  0.04259871318936348\n",
      "9/20 epoch at batch 180 with loss 0.14064305759966372  and val of  0.04164078086614609\n",
      "9/20 epoch at batch 190 with loss 0.09599631279706955  and val of  0.049722820520401\n",
      "9/20 epoch at batch 200 with loss 0.11007276438176632  and val of  0.045618847012519836\n",
      "9/20 epoch at batch 210 with loss 0.10184344314038754  and val of  0.051754917949438095\n",
      "9/20 epoch at batch 220 with loss 0.1267925061285496  and val of  0.052331604063510895\n",
      "9/20 epoch at batch 230 with loss 0.13320836797356606  and val of  0.049120280891656876\n",
      "9/20 epoch at batch 240 with loss 0.14622123390436173  and val of  0.04193300008773804\n",
      "9/20 epoch at batch 250 with loss 0.11301396414637566  and val of  0.04709017276763916\n",
      "9/20 epoch at batch 260 with loss 0.10968671143054962  and val of  0.04239124432206154\n",
      "9/20 epoch at batch 270 with loss 0.09920739904046058  and val of  0.04658561944961548\n",
      "9/20 epoch at batch 280 with loss 0.11886699311435223  and val of  0.042961928993463516\n",
      "9/20 epoch at batch 290 with loss 0.14446600377559662  and val of  0.045008521527051926\n",
      "10/20 epoch at batch 10 with loss 0.10009437538683415  and val of  0.042995717376470566\n",
      "10/20 epoch at batch 20 with loss 0.09699522033333778  and val of  0.04893431067466736\n",
      "10/20 epoch at batch 30 with loss 0.13468868657946587  and val of  0.04970137029886246\n",
      "10/20 epoch at batch 40 with loss 0.11987201273441314  and val of  0.0481603629887104\n",
      "10/20 epoch at batch 50 with loss 0.12755611017346383  and val of  0.045616667717695236\n",
      "10/20 epoch at batch 60 with loss 0.12045873068273068  and val of  0.043267104774713516\n",
      "10/20 epoch at batch 70 with loss 0.10145726837217808  and val of  0.047242943197488785\n",
      "10/20 epoch at batch 80 with loss 0.09853082671761512  and val of  0.04238217696547508\n",
      "10/20 epoch at batch 90 with loss 0.10487508475780487  and val of  0.044251129031181335\n",
      "10/20 epoch at batch 100 with loss 0.13605526685714722  and val of  0.04270545393228531\n",
      "10/20 epoch at batch 110 with loss 0.11335782296955585  and val of  0.043675702065229416\n",
      "10/20 epoch at batch 120 with loss 0.11500196401029825  and val of  0.04738878458738327\n",
      "10/20 epoch at batch 130 with loss 0.09778401367366314  and val of  0.04971747472882271\n",
      "10/20 epoch at batch 140 with loss 0.10196269229054451  and val of  0.04606735333800316\n",
      "10/20 epoch at batch 150 with loss 0.12527795732021332  and val of  0.06468266248703003\n",
      "10/20 epoch at batch 160 with loss 0.13063130378723145  and val of  0.042764678597450256\n",
      "10/20 epoch at batch 170 with loss 0.09661357440054416  and val of  0.04388361796736717\n",
      "10/20 epoch at batch 180 with loss 0.11072838231921196  and val of  0.049836572259664536\n",
      "10/20 epoch at batch 190 with loss 0.10603363998234272  and val of  0.04514309763908386\n",
      "10/20 epoch at batch 200 with loss 0.09826816618442535  and val of  0.04904452711343765\n",
      "10/20 epoch at batch 210 with loss 0.13164140805602073  and val of  0.0517452135682106\n",
      "10/20 epoch at batch 220 with loss 0.11229600310325623  and val of  0.04774957150220871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/20 epoch at batch 230 with loss 0.11889387480914593  and val of  0.049009352922439575\n",
      "10/20 epoch at batch 240 with loss 0.10080769136548043  and val of  0.05366590991616249\n",
      "10/20 epoch at batch 250 with loss 0.09353114850819111  and val of  0.05714218690991402\n",
      "10/20 epoch at batch 260 with loss 0.1022552102804184  and val of  0.052716463804244995\n",
      "10/20 epoch at batch 270 with loss 0.09418339729309082  and val of  0.050726618617773056\n",
      "10/20 epoch at batch 280 with loss 0.11670061126351357  and val of  0.0477333702147007\n",
      "10/20 epoch at batch 290 with loss 0.09299135282635689  and val of  0.04590265452861786\n",
      "11/20 epoch at batch 10 with loss 0.11289463266730308  and val of  0.0507250539958477\n",
      "11/20 epoch at batch 20 with loss 0.12781688012182713  and val of  0.05196176841855049\n",
      "11/20 epoch at batch 30 with loss 0.09902316778898239  and val of  0.045386478304862976\n",
      "11/20 epoch at batch 40 with loss 0.10277350097894669  and val of  0.05307525396347046\n",
      "11/20 epoch at batch 50 with loss 0.1253770850598812  and val of  0.05562634393572807\n",
      "11/20 epoch at batch 60 with loss 0.09726253151893616  and val of  0.05402150750160217\n",
      "11/20 epoch at batch 70 with loss 0.11457343026995659  and val of  0.05327808856964111\n",
      "11/20 epoch at batch 80 with loss 0.10651582777500153  and val of  0.04466709494590759\n",
      "11/20 epoch at batch 90 with loss 0.08546530939638615  and val of  0.055859748274087906\n",
      "11/20 epoch at batch 100 with loss 0.12252795584499836  and val of  0.044127874076366425\n",
      "11/20 epoch at batch 110 with loss 0.10879087876528501  and val of  0.045299429446458817\n",
      "11/20 epoch at batch 120 with loss 0.10108042769134044  and val of  0.051492370665073395\n",
      "11/20 epoch at batch 130 with loss 0.10314159281551838  and val of  0.05337134003639221\n",
      "11/20 epoch at batch 140 with loss 0.10179472472518683  and val of  0.05142448469996452\n",
      "11/20 epoch at batch 150 with loss 0.10867599099874496  and val of  0.050971854478120804\n",
      "11/20 epoch at batch 160 with loss 0.12103990763425827  and val of  0.04766726493835449\n",
      "11/20 epoch at batch 170 with loss 0.09794504307210446  and val of  0.050249140709638596\n",
      "11/20 epoch at batch 180 with loss 0.09009604826569557  and val of  0.04309142380952835\n",
      "11/20 epoch at batch 190 with loss 0.11709407195448876  and val of  0.05731707438826561\n",
      "11/20 epoch at batch 200 with loss 0.11318708211183548  and val of  0.05075005069375038\n",
      "11/20 epoch at batch 210 with loss 0.10563591383397579  and val of  0.044468432664871216\n",
      "11/20 epoch at batch 220 with loss 0.1394756942987442  and val of  0.04202117770910263\n",
      "11/20 epoch at batch 230 with loss 0.1228792380541563  and val of  0.05343661457300186\n",
      "11/20 epoch at batch 240 with loss 0.14182550609111785  and val of  0.044976189732551575\n",
      "11/20 epoch at batch 250 with loss 0.11688105352222919  and val of  0.039698708802461624\n",
      "11/20 epoch at batch 260 with loss 0.09198399372398854  and val of  0.043886132538318634\n",
      "11/20 epoch at batch 270 with loss 0.11773023791611195  and val of  0.0447087399661541\n",
      "11/20 epoch at batch 280 with loss 0.10254796519875527  and val of  0.05085622891783714\n",
      "11/20 epoch at batch 290 with loss 0.09301496855914593  and val of  0.049741268157958984\n",
      "12/20 epoch at batch 10 with loss 0.0931138876825571  and val of  0.04598700627684593\n",
      "12/20 epoch at batch 20 with loss 0.08899543769657611  and val of  0.04575497657060623\n",
      "12/20 epoch at batch 30 with loss 0.09807346016168594  and val of  0.04478078708052635\n",
      "12/20 epoch at batch 40 with loss 0.09936869442462921  and val of  0.043943166732788086\n",
      "12/20 epoch at batch 50 with loss 0.10165635086596012  and val of  0.04317835718393326\n",
      "12/20 epoch at batch 60 with loss 0.1053652349859476  and val of  0.04043521359562874\n",
      "12/20 epoch at batch 70 with loss 0.09532608985900878  and val of  0.043608762323856354\n",
      "12/20 epoch at batch 80 with loss 0.07354026474058628  and val of  0.04427343234419823\n",
      "12/20 epoch at batch 90 with loss 0.10398763939738273  and val of  0.04600602015852928\n",
      "12/20 epoch at batch 100 with loss 0.07968162316828967  and val of  0.04741177335381508\n",
      "12/20 epoch at batch 110 with loss 0.10475825145840645  and val of  0.04039325565099716\n",
      "12/20 epoch at batch 120 with loss 0.09999982230365276  and val of  0.04614444077014923\n",
      "12/20 epoch at batch 130 with loss 0.09740882068872452  and val of  0.04405086115002632\n",
      "12/20 epoch at batch 140 with loss 0.0978327177464962  and val of  0.04026280343532562\n",
      "12/20 epoch at batch 150 with loss 0.10456240922212601  and val of  0.0493507906794548\n",
      "12/20 epoch at batch 160 with loss 0.09109786488115787  and val of  0.040295183658599854\n",
      "12/20 epoch at batch 170 with loss 0.08213388845324517  and val of  0.048004601150751114\n",
      "12/20 epoch at batch 180 with loss 0.09088585786521435  and val of  0.049001820385456085\n",
      "12/20 epoch at batch 190 with loss 0.10343590639531612  and val of  0.046318549662828445\n",
      "12/20 epoch at batch 200 with loss 0.10071393102407455  and val of  0.04444585368037224\n",
      "12/20 epoch at batch 210 with loss 0.10944297760725022  and val of  0.04353697597980499\n",
      "12/20 epoch at batch 220 with loss 0.1467946097254753  and val of  0.03942970931529999\n",
      "12/20 epoch at batch 230 with loss 0.09133525639772415  and val of  0.04606427997350693\n",
      "12/20 epoch at batch 240 with loss 0.14201403856277467  and val of  0.04619865491986275\n",
      "12/20 epoch at batch 250 with loss 0.11530850008130074  and val of  0.04252491891384125\n",
      "12/20 epoch at batch 260 with loss 0.11569547969847918  and val of  0.04058998450636864\n",
      "12/20 epoch at batch 270 with loss 0.12021407335996628  and val of  0.03759961202740669\n",
      "12/20 epoch at batch 280 with loss 0.11109304428100586  and val of  0.04251305013895035\n",
      "12/20 epoch at batch 290 with loss 0.07506502456963063  and val of  0.04206637665629387\n",
      "13/20 epoch at batch 10 with loss 0.12930858209729196  and val of  0.03600534051656723\n",
      "13/20 epoch at batch 20 with loss 0.07864424660801887  and val of  0.03978331387042999\n",
      "13/20 epoch at batch 30 with loss 0.080299461632967  and val of  0.04153117164969444\n",
      "13/20 epoch at batch 40 with loss 0.083179762493819  and val of  0.0376301109790802\n",
      "13/20 epoch at batch 50 with loss 0.09080931283533573  and val of  0.039066508412361145\n",
      "13/20 epoch at batch 60 with loss 0.08086278140544892  and val of  0.034980665892362595\n",
      "13/20 epoch at batch 70 with loss 0.08825872801244258  and val of  0.0432111881673336\n",
      "13/20 epoch at batch 80 with loss 0.07262891046702862  and val of  0.05418363958597183\n",
      "13/20 epoch at batch 90 with loss 0.11167706027626992  and val of  0.03372679650783539\n",
      "13/20 epoch at batch 100 with loss 0.08913960419595242  and val of  0.040779612958431244\n",
      "13/20 epoch at batch 110 with loss 0.09601621404290199  and val of  0.04197810962796211\n",
      "13/20 epoch at batch 120 with loss 0.11546134762465954  and val of  0.03802771493792534\n",
      "13/20 epoch at batch 130 with loss 0.11910395249724388  and val of  0.03760027140378952\n",
      "13/20 epoch at batch 140 with loss 0.09426571354269982  and val of  0.04091251641511917\n",
      "13/20 epoch at batch 150 with loss 0.08556456379592418  and val of  0.042060863226652145\n",
      "13/20 epoch at batch 160 with loss 0.0937141228467226  and val of  0.0365927629172802\n",
      "13/20 epoch at batch 170 with loss 0.09960012007504701  and val of  0.03753827512264252\n",
      "13/20 epoch at batch 180 with loss 0.1156098060309887  and val of  0.038854677230119705\n",
      "13/20 epoch at batch 190 with loss 0.07371910456568002  and val of  0.0380103625357151\n",
      "13/20 epoch at batch 200 with loss 0.10184499323368072  and val of  0.03779388219118118\n",
      "13/20 epoch at batch 210 with loss 0.12255361825227737  and val of  0.04902435839176178\n",
      "13/20 epoch at batch 220 with loss 0.08887964524328709  and val of  0.041534483432769775\n",
      "13/20 epoch at batch 230 with loss 0.10077550075948238  and val of  0.03693419322371483\n",
      "13/20 epoch at batch 240 with loss 0.08887847792357206  and val of  0.0352044478058815\n",
      "13/20 epoch at batch 250 with loss 0.10305480025708676  and val of  0.04148704558610916\n",
      "13/20 epoch at batch 260 with loss 0.10858564004302025  and val of  0.04541337862610817\n",
      "13/20 epoch at batch 270 with loss 0.12605277225375175  and val of  0.03584807366132736\n",
      "13/20 epoch at batch 280 with loss 0.0803337536752224  and val of  0.04051534831523895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/20 epoch at batch 290 with loss 0.10220018960535526  and val of  0.036019109189510345\n",
      "14/20 epoch at batch 10 with loss 0.11060020923614503  and val of  0.03906624764204025\n",
      "14/20 epoch at batch 20 with loss 0.08384739868342876  and val of  0.03516799956560135\n",
      "14/20 epoch at batch 30 with loss 0.10105196125805378  and val of  0.042200177907943726\n",
      "14/20 epoch at batch 40 with loss 0.09297335632145405  and val of  0.041367046535015106\n",
      "14/20 epoch at batch 50 with loss 0.08920106999576091  and val of  0.03954680263996124\n",
      "14/20 epoch at batch 60 with loss 0.10635529458522797  and val of  0.038232650607824326\n",
      "14/20 epoch at batch 70 with loss 0.09910842962563038  and val of  0.040389496833086014\n",
      "14/20 epoch at batch 80 with loss 0.07252391502261162  and val of  0.04082363843917847\n",
      "14/20 epoch at batch 90 with loss 0.10045133940875531  and val of  0.03972315788269043\n",
      "14/20 epoch at batch 100 with loss 0.10342501569539309  and val of  0.03560855612158775\n",
      "14/20 epoch at batch 110 with loss 0.09511809628456831  and val of  0.048152271658182144\n",
      "14/20 epoch at batch 120 with loss 0.09476293995976448  and val of  0.03972770646214485\n",
      "14/20 epoch at batch 130 with loss 0.06561051234602928  and val of  0.039645981043577194\n",
      "14/20 epoch at batch 140 with loss 0.09939830973744393  and val of  0.04128669947385788\n",
      "14/20 epoch at batch 150 with loss 0.0950867399573326  and val of  0.03610912337899208\n",
      "14/20 epoch at batch 160 with loss 0.11205453742295504  and val of  0.04254690930247307\n",
      "14/20 epoch at batch 170 with loss 0.10963575318455696  and val of  0.04185149073600769\n",
      "14/20 epoch at batch 180 with loss 0.05972946304827929  and val of  0.036766525357961655\n",
      "14/20 epoch at batch 190 with loss 0.07046744413673878  and val of  0.03875291347503662\n",
      "14/20 epoch at batch 200 with loss 0.06797800585627556  and val of  0.038736164569854736\n",
      "14/20 epoch at batch 210 with loss 0.07623894736170769  and val of  0.0358455665409565\n",
      "14/20 epoch at batch 220 with loss 0.08084040731191636  and val of  0.0385211780667305\n",
      "14/20 epoch at batch 230 with loss 0.07864775061607361  and val of  0.033928100019693375\n",
      "14/20 epoch at batch 240 with loss 0.08936281241476536  and val of  0.03855296969413757\n",
      "14/20 epoch at batch 250 with loss 0.07285506073385477  and val of  0.03521845489740372\n",
      "14/20 epoch at batch 260 with loss 0.08616712391376495  and val of  0.048649292439222336\n",
      "14/20 epoch at batch 270 with loss 0.10125684021040797  and val of  0.04539477452635765\n",
      "14/20 epoch at batch 280 with loss 0.13043127432465554  and val of  0.03767666593194008\n",
      "14/20 epoch at batch 290 with loss 0.11506835520267486  and val of  0.039536163210868835\n",
      "15/20 epoch at batch 10 with loss 0.08452082835137845  and val of  0.03920663148164749\n",
      "15/20 epoch at batch 20 with loss 0.0932209575548768  and val of  0.0391341894865036\n",
      "15/20 epoch at batch 30 with loss 0.0749957162886858  and val of  0.03824976086616516\n",
      "15/20 epoch at batch 40 with loss 0.06694443207234144  and val of  0.031443290412425995\n",
      "15/20 epoch at batch 50 with loss 0.08340952191501856  and val of  0.041386909782886505\n",
      "15/20 epoch at batch 60 with loss 0.08939663134515285  and val of  0.04817332327365875\n",
      "15/20 epoch at batch 70 with loss 0.08107680790126323  and val of  0.03861197084188461\n",
      "15/20 epoch at batch 80 with loss 0.08017206769436598  and val of  0.03892209380865097\n",
      "15/20 epoch at batch 90 with loss 0.1050019957125187  and val of  0.04057186469435692\n",
      "15/20 epoch at batch 100 with loss 0.11406708806753159  and val of  0.03764811530709267\n",
      "15/20 epoch at batch 110 with loss 0.09456907454878091  and val of  0.03804389759898186\n",
      "15/20 epoch at batch 120 with loss 0.06666853539645672  and val of  0.037023626267910004\n",
      "15/20 epoch at batch 130 with loss 0.07817989084869623  and val of  0.03733592852950096\n",
      "15/20 epoch at batch 140 with loss 0.07776431143283843  and val of  0.037894584238529205\n",
      "15/20 epoch at batch 150 with loss 0.08245133366435767  and val of  0.04106830433011055\n",
      "15/20 epoch at batch 160 with loss 0.10065552890300751  and val of  0.03476918488740921\n",
      "15/20 epoch at batch 170 with loss 0.09329676944762469  and val of  0.038753364235162735\n",
      "15/20 epoch at batch 180 with loss 0.09953619688749313  and val of  0.0352223701775074\n",
      "15/20 epoch at batch 190 with loss 0.09390889555215835  and val of  0.035496026277542114\n",
      "15/20 epoch at batch 200 with loss 0.07712683789432048  and val of  0.033165059983730316\n",
      "15/20 epoch at batch 210 with loss 0.0900277340784669  and val of  0.03892980143427849\n",
      "15/20 epoch at batch 220 with loss 0.08893735241144896  and val of  0.035828784108161926\n",
      "15/20 epoch at batch 230 with loss 0.10692154914140702  and val of  0.042104173451662064\n",
      "15/20 epoch at batch 240 with loss 0.11782825887203216  and val of  0.04071085527539253\n",
      "15/20 epoch at batch 250 with loss 0.07234002724289894  and val of  0.04099401459097862\n",
      "15/20 epoch at batch 260 with loss 0.07467862889170647  and val of  0.041939180344343185\n",
      "15/20 epoch at batch 270 with loss 0.1015835840255022  and val of  0.039686400443315506\n",
      "15/20 epoch at batch 280 with loss 0.11168386973440647  and val of  0.036948222666978836\n",
      "15/20 epoch at batch 290 with loss 0.08576977783814073  and val of  0.04034901037812233\n",
      "16/20 epoch at batch 10 with loss 0.09813955277204514  and val of  0.03887287899851799\n",
      "16/20 epoch at batch 20 with loss 0.09691213145852089  and val of  0.03274642303586006\n",
      "16/20 epoch at batch 30 with loss 0.09509627744555474  and val of  0.03483954071998596\n",
      "16/20 epoch at batch 40 with loss 0.06996268704533577  and val of  0.033282648772001266\n",
      "16/20 epoch at batch 50 with loss 0.08897271566092968  and val of  0.03511630371212959\n",
      "16/20 epoch at batch 60 with loss 0.11621121726930142  and val of  0.033209823071956635\n",
      "16/20 epoch at batch 70 with loss 0.10356832221150399  and val of  0.037058863788843155\n",
      "16/20 epoch at batch 80 with loss 0.09913156405091286  and val of  0.03168174996972084\n",
      "16/20 epoch at batch 90 with loss 0.08712860271334648  and val of  0.03590390831232071\n",
      "16/20 epoch at batch 100 with loss 0.09572528935968876  and val of  0.03720979019999504\n",
      "16/20 epoch at batch 110 with loss 0.08592018149793149  and val of  0.0385320819914341\n",
      "16/20 epoch at batch 120 with loss 0.07852577678859234  and val of  0.038292475044727325\n",
      "16/20 epoch at batch 130 with loss 0.0932305671274662  and val of  0.03865466266870499\n",
      "16/20 epoch at batch 140 with loss 0.06670683287084103  and val of  0.038266416639089584\n",
      "16/20 epoch at batch 150 with loss 0.06943862289190292  and val of  0.03599577024579048\n",
      "16/20 epoch at batch 160 with loss 0.09706116411834956  and val of  0.03713935986161232\n",
      "16/20 epoch at batch 170 with loss 0.09109809063374996  and val of  0.04003161936998367\n",
      "16/20 epoch at batch 180 with loss 0.08963274359703063  and val of  0.03528211638331413\n",
      "16/20 epoch at batch 190 with loss 0.1147081159055233  and val of  0.03464411199092865\n",
      "16/20 epoch at batch 200 with loss 0.062279007956385614  and val of  0.03259080648422241\n",
      "16/20 epoch at batch 210 with loss 0.0890105839818716  and val of  0.03938313573598862\n",
      "16/20 epoch at batch 220 with loss 0.06932718120515347  and val of  0.04367511719465256\n",
      "16/20 epoch at batch 230 with loss 0.08247297182679177  and val of  0.03830283135175705\n",
      "16/20 epoch at batch 240 with loss 0.10681412704288959  and val of  0.03418919816613197\n",
      "16/20 epoch at batch 250 with loss 0.07494573779404164  and val of  0.03435096889734268\n",
      "16/20 epoch at batch 260 with loss 0.08383493013679981  and val of  0.03478752821683884\n",
      "16/20 epoch at batch 270 with loss 0.07942382022738456  and val of  0.03549233824014664\n",
      "16/20 epoch at batch 280 with loss 0.09703961946070194  and val of  0.038977574557065964\n",
      "16/20 epoch at batch 290 with loss 0.08345095217227935  and val of  0.03686293214559555\n",
      "17/20 epoch at batch 10 with loss 0.10068747811019421  and val of  0.03382577374577522\n",
      "17/20 epoch at batch 20 with loss 0.08857801128178835  and val of  0.030865216627717018\n",
      "17/20 epoch at batch 30 with loss 0.08033906407654286  and val of  0.030468693003058434\n",
      "17/20 epoch at batch 40 with loss 0.07085097478702665  and val of  0.034220319241285324\n",
      "17/20 epoch at batch 50 with loss 0.08465786091983318  and val of  0.037103768438100815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/20 epoch at batch 60 with loss 0.09565054588019847  and val of  0.033204447478055954\n",
      "17/20 epoch at batch 70 with loss 0.08548183478415013  and val of  0.03450968489050865\n",
      "17/20 epoch at batch 80 with loss 0.08522621132433414  and val of  0.03694402799010277\n",
      "17/20 epoch at batch 90 with loss 0.08106979504227638  and val of  0.038520921021699905\n",
      "17/20 epoch at batch 100 with loss 0.07024675756692886  and val of  0.03674217313528061\n",
      "17/20 epoch at batch 110 with loss 0.12851243317127228  and val of  0.039227042347192764\n",
      "17/20 epoch at batch 120 with loss 0.07735123112797737  and val of  0.03965013474225998\n",
      "17/20 epoch at batch 130 with loss 0.08289913609623908  and val of  0.04180599004030228\n",
      "17/20 epoch at batch 140 with loss 0.08730986639857292  and val of  0.038889847695827484\n",
      "17/20 epoch at batch 150 with loss 0.06118447221815586  and val of  0.037410229444503784\n",
      "17/20 epoch at batch 160 with loss 0.06127188764512539  and val of  0.035656195133924484\n",
      "17/20 epoch at batch 170 with loss 0.08900155406445265  and val of  0.03890032693743706\n",
      "17/20 epoch at batch 180 with loss 0.0971529845148325  and val of  0.03718522936105728\n",
      "17/20 epoch at batch 190 with loss 0.08319916594773531  and val of  0.043102629482746124\n",
      "17/20 epoch at batch 200 with loss 0.0965618621557951  and val of  0.034203387796878815\n",
      "17/20 epoch at batch 210 with loss 0.08296296261250972  and val of  0.03679705411195755\n",
      "17/20 epoch at batch 220 with loss 0.10204467512667179  and val of  0.0349387489259243\n",
      "17/20 epoch at batch 230 with loss 0.07817297168076039  and val of  0.037290021777153015\n",
      "17/20 epoch at batch 240 with loss 0.09110084921121597  and val of  0.03817155957221985\n",
      "17/20 epoch at batch 250 with loss 0.09245487321168185  and val of  0.04313121363520622\n",
      "17/20 epoch at batch 260 with loss 0.09211959643289447  and val of  0.03743254020810127\n",
      "17/20 epoch at batch 270 with loss 0.07867408506572246  and val of  0.035948656499385834\n",
      "17/20 epoch at batch 280 with loss 0.06862451182678342  and val of  0.036165885627269745\n",
      "17/20 epoch at batch 290 with loss 0.09018217362463474  and val of  0.04038527235388756\n",
      "18/20 epoch at batch 10 with loss 0.09432848654687405  and val of  0.04844736307859421\n",
      "18/20 epoch at batch 20 with loss 0.07631189823150634  and val of  0.03928274288773537\n",
      "18/20 epoch at batch 30 with loss 0.06281469352543353  and val of  0.03908170759677887\n",
      "18/20 epoch at batch 40 with loss 0.061433596257120374  and val of  0.04154047742486\n",
      "18/20 epoch at batch 50 with loss 0.09176855273544789  and val of  0.03458862751722336\n",
      "18/20 epoch at batch 60 with loss 0.11125463172793389  and val of  0.0302505511790514\n",
      "18/20 epoch at batch 70 with loss 0.06770683154463768  and val of  0.03602290153503418\n",
      "18/20 epoch at batch 80 with loss 0.08936967365443707  and val of  0.035993337631225586\n",
      "18/20 epoch at batch 90 with loss 0.09487178847193718  and val of  0.035244282335042953\n",
      "18/20 epoch at batch 100 with loss 0.07845501527190209  and val of  0.04050144925713539\n",
      "18/20 epoch at batch 110 with loss 0.07583781890571117  and val of  0.03735197335481644\n",
      "18/20 epoch at batch 120 with loss 0.07219043038785458  and val of  0.03564450144767761\n",
      "18/20 epoch at batch 130 with loss 0.0982402041554451  and val of  0.03811713680624962\n",
      "18/20 epoch at batch 140 with loss 0.07368281427770854  and val of  0.03769337013363838\n",
      "18/20 epoch at batch 150 with loss 0.09038018900901079  and val of  0.03796068951487541\n",
      "18/20 epoch at batch 160 with loss 0.06881787460297346  and val of  0.03445048630237579\n",
      "18/20 epoch at batch 170 with loss 0.09122127927839756  and val of  0.03332027792930603\n",
      "18/20 epoch at batch 180 with loss 0.0843129750341177  and val of  0.028262261301279068\n",
      "18/20 epoch at batch 190 with loss 0.07350527830421924  and val of  0.029382286593317986\n",
      "18/20 epoch at batch 200 with loss 0.08488872852176428  and val of  0.03646628558635712\n",
      "18/20 epoch at batch 210 with loss 0.07895723916590214  and val of  0.03518855571746826\n",
      "18/20 epoch at batch 220 with loss 0.07264050543308258  and val of  0.034478116780519485\n",
      "18/20 epoch at batch 230 with loss 0.0764188390225172  and val of  0.044543277472257614\n",
      "18/20 epoch at batch 240 with loss 0.08033701740205287  and val of  0.03154970332980156\n",
      "18/20 epoch at batch 250 with loss 0.08658943884074688  and val of  0.03146376088261604\n",
      "18/20 epoch at batch 260 with loss 0.05913751646876335  and val of  0.0364324152469635\n",
      "18/20 epoch at batch 270 with loss 0.06454241741448641  and val of  0.03262259438633919\n",
      "18/20 epoch at batch 280 with loss 0.09267145246267319  and val of  0.03555057942867279\n",
      "18/20 epoch at batch 290 with loss 0.08623096235096454  and val of  0.03765178844332695\n",
      "19/20 epoch at batch 10 with loss 0.08844997622072696  and val of  0.03495211526751518\n",
      "19/20 epoch at batch 20 with loss 0.07272735619917511  and val of  0.038189928978681564\n",
      "19/20 epoch at batch 30 with loss 0.08671028614044189  and val of  0.03375278413295746\n",
      "19/20 epoch at batch 40 with loss 0.061082216538488866  and val of  0.037718236446380615\n",
      "19/20 epoch at batch 50 with loss 0.0808006215840578  and val of  0.034313566982746124\n",
      "19/20 epoch at batch 60 with loss 0.06142561510205269  and val of  0.03559807315468788\n",
      "19/20 epoch at batch 70 with loss 0.06549970339983702  and val of  0.03928808867931366\n",
      "19/20 epoch at batch 80 with loss 0.06462106574326754  and val of  0.04082628712058067\n",
      "19/20 epoch at batch 90 with loss 0.09805713333189488  and val of  0.030150100588798523\n",
      "19/20 epoch at batch 100 with loss 0.0765168173238635  and val of  0.032019004225730896\n",
      "19/20 epoch at batch 110 with loss 0.10124985985457897  and val of  0.030081309378147125\n",
      "19/20 epoch at batch 120 with loss 0.08073847703635692  and val of  0.035184480249881744\n",
      "19/20 epoch at batch 130 with loss 0.07785613350570202  and val of  0.033546581864356995\n",
      "19/20 epoch at batch 140 with loss 0.08606020621955394  and val of  0.03498368710279465\n",
      "19/20 epoch at batch 150 with loss 0.07222569715231657  and val of  0.032617438584566116\n",
      "19/20 epoch at batch 160 with loss 0.0920949038118124  and val of  0.0325612835586071\n",
      "19/20 epoch at batch 170 with loss 0.1014410849660635  and val of  0.03706947714090347\n",
      "19/20 epoch at batch 180 with loss 0.08842510320246219  and val of  0.038011692464351654\n",
      "19/20 epoch at batch 190 with loss 0.10857404153794051  and val of  0.031418073922395706\n",
      "19/20 epoch at batch 200 with loss 0.0766645571216941  and val of  0.030478360131382942\n",
      "19/20 epoch at batch 210 with loss 0.06607569307088852  and val of  0.029613589867949486\n",
      "19/20 epoch at batch 220 with loss 0.07318547759205103  and val of  0.03368349373340607\n",
      "19/20 epoch at batch 230 with loss 0.06325834393501281  and val of  0.030342359095811844\n",
      "19/20 epoch at batch 240 with loss 0.0740462277084589  and val of  0.036496855318546295\n",
      "19/20 epoch at batch 250 with loss 0.0691951798275113  and val of  0.03460761159658432\n",
      "19/20 epoch at batch 260 with loss 0.06038351785391569  and val of  0.034888267517089844\n",
      "19/20 epoch at batch 270 with loss 0.08629776779562234  and val of  0.034646399319171906\n",
      "19/20 epoch at batch 280 with loss 0.07742779813706875  and val of  0.03972642496228218\n",
      "19/20 epoch at batch 290 with loss 0.09589321501553058  and val of  0.03183548152446747\n",
      "20/20 epoch at batch 10 with loss 0.052725864201784135  and val of  0.037444524466991425\n",
      "20/20 epoch at batch 20 with loss 0.06299474146217107  and val of  0.044678229838609695\n",
      "20/20 epoch at batch 30 with loss 0.0610259011387825  and val of  0.03661829233169556\n",
      "20/20 epoch at batch 40 with loss 0.06690886281430722  and val of  0.03455748409032822\n",
      "20/20 epoch at batch 50 with loss 0.07661899924278259  and val of  0.03964395076036453\n",
      "20/20 epoch at batch 60 with loss 0.1097437672317028  and val of  0.03190181031823158\n",
      "20/20 epoch at batch 70 with loss 0.06362348068505526  and val of  0.03182829171419144\n",
      "20/20 epoch at batch 80 with loss 0.08270785324275494  and val of  0.03441685065627098\n",
      "20/20 epoch at batch 90 with loss 0.08146170563995839  and val of  0.03248986229300499\n",
      "20/20 epoch at batch 100 with loss 0.07705134060233831  and val of  0.032710686326026917\n",
      "20/20 epoch at batch 110 with loss 0.09040441028773785  and val of  0.03144996613264084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 epoch at batch 120 with loss 0.0743096588179469  and val of  0.03178934380412102\n",
      "20/20 epoch at batch 130 with loss 0.0678794164210558  and val of  0.03439609333872795\n",
      "20/20 epoch at batch 140 with loss 0.08596557322889567  and val of  0.03062068112194538\n",
      "20/20 epoch at batch 150 with loss 0.07769159488379955  and val of  0.03355695307254791\n",
      "20/20 epoch at batch 160 with loss 0.06034015119075775  and val of  0.03945092856884003\n",
      "20/20 epoch at batch 170 with loss 0.08104556873440742  and val of  0.031158853322267532\n",
      "20/20 epoch at batch 180 with loss 0.08533484153449536  and val of  0.03361024335026741\n",
      "20/20 epoch at batch 190 with loss 0.07454095594584942  and val of  0.029783053323626518\n",
      "20/20 epoch at batch 200 with loss 0.06110850740224123  and val of  0.03000568225979805\n",
      "20/20 epoch at batch 210 with loss 0.0774798545986414  and val of  0.031337860971689224\n",
      "20/20 epoch at batch 220 with loss 0.09567496404051781  and val of  0.03467389568686485\n",
      "20/20 epoch at batch 230 with loss 0.07346118614077568  and val of  0.04240814223885536\n",
      "20/20 epoch at batch 240 with loss 0.10141862034797669  and val of  0.039807889610528946\n",
      "20/20 epoch at batch 250 with loss 0.087451858446002  and val of  0.034958820790052414\n",
      "20/20 epoch at batch 260 with loss 0.07135672643780708  and val of  0.035035550594329834\n",
      "20/20 epoch at batch 270 with loss 0.1315709561109543  and val of  0.029052184894680977\n",
      "20/20 epoch at batch 280 with loss 0.08927777949720621  and val of  0.03386856988072395\n",
      "20/20 epoch at batch 290 with loss 0.08621110469102859  and val of  0.03470582515001297\n"
     ]
    }
   ],
   "source": [
    "#the training part :D\n",
    "\n",
    "epoches = 20 #number of iterations over the data\n",
    "\n",
    "# preparing the net for training\n",
    "net.train()\n",
    "\n",
    "for epoch in range (epoches):\n",
    "    \n",
    "    curr_loss = 0\n",
    "    \n",
    "    # training on batches of data from out data loader\n",
    "    for batch_num , data in enumerate(data_train):\n",
    "        \n",
    "        net.train()\n",
    "        \n",
    "        # the input images and their corresponding labels\n",
    "        image_batch = data[0].unsqueeze(1)\n",
    "        labels_batch = data[1]\n",
    "        \n",
    "        # forward pass to get outputs\n",
    "        probas = net(image_batch)\n",
    "        \n",
    "        # calculate the loss between the probabilities and the labels\n",
    "        loss_batch = loss(probas,labels_batch.to(int))\n",
    "        \n",
    "        # zero the parameter (weight) gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # backward pass to calculate the weight gradients\n",
    "        loss_batch.backward()\n",
    "        \n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        #adding the loss of that batch to our curr loss variable\n",
    "        curr_loss += loss_batch.item()\n",
    "        \n",
    "        #every 10 batches\n",
    "        if (batch_num+1) % 10 == 0 :\n",
    "            \n",
    "            #making our model in the evaluation mode\n",
    "            net.eval()\n",
    "            \n",
    "            #making predictions on the val data\n",
    "            probas_val = net(images_val.unsqueeze(1))\n",
    "            \n",
    "            #calculating the validation loss\n",
    "            loss_val = loss(probas_val , labels_val.to(int)).item()\n",
    "            \n",
    "            print('{}/20 epoch at batch {} with loss {}  and val of  {}'.format(epoch+1, batch_num+1 , curr_loss/10 , loss_val ) )\n",
    "            curr_loss = 0\n",
    "            \n",
    "            net.train()\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the models parameter after the training\n",
    "\n",
    "model_dir = ''\n",
    "model_name = 'mnist_model_NLL_6.pt'\n",
    "\n",
    "torch.save(net.state_dict(), model_dir+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#preprocessing the test images \n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "images_test = test.to_numpy()\n",
    "\n",
    "images_test = images_test.reshape((28000,28,28))\n",
    "\n",
    "images_test = images_test.astype(np.uint8)\n",
    "\n",
    "augmented_images_test = torch.zeros(images_test.shape)\n",
    "    \n",
    "image_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(0.1308 , 0.3083)\n",
    "                                         ])\n",
    "    \n",
    "for indx , image in enumerate(images_test) :\n",
    "    augmented_images_test[indx] = image_transform(image.reshape(28,28,1))\n",
    "        \n",
    "\n",
    "\n",
    "images_test = augmented_images_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally! the time to tell fortunes !!\n",
    "net.eval()\n",
    "\n",
    "images_test = images_test.unsqueeze(1) #from (N,28,28) to (N,1,28,28)\n",
    "probas = net(images_test)\n",
    "\n",
    "predictions = probas.argmax(dim=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('sample_submission.csv')\n",
    "submit['Label'] = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3\n",
       "5        6      7\n",
       "6        7      0\n",
       "7        8      3\n",
       "8        9      0\n",
       "9       10      3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ab0e2b97f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images_test[8].squeeze(0),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
